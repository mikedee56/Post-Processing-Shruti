[tool:pytest]
# Story 5.5: Testing & Quality Assurance Framework Configuration
# Enhanced pytest configuration for comprehensive testing framework

# Test discovery patterns
python_files = test_*.py *_test.py
python_classes = Test* *Tests
python_functions = test_*

# Test paths
testpaths = 
    tests
    qa

# Minimum version
minversion = 7.0

# Pytest options with comprehensive coverage and quality assurance
addopts = 
    --verbose
    --tb=short
    --strict-markers
    --strict-config
    --color=yes
    --cov=src
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-fail-under=90
    --durations=10
    --junit-xml=junit.xml

# Custom markers for test organization
markers =
    # Story-specific markers
    story_4_5: Story 4.5 specific tests
    story_5_5: Story 5.5 Testing Framework tests
    epic4_readiness: Epic 4 readiness validation tests
    
    # Test type markers
    unit: Unit tests for individual components
    integration: Integration tests for component interactions
    performance: Performance and regression tests
    validation: Framework and quality validation tests
    
    # Domain-specific markers
    academic: Academic standards and publication tests
    sanskrit: Sanskrit/Hindi processing tests
    quality_assurance: Quality assurance and monitoring tests
    golden_dataset: Golden dataset validation tests
    
    # Execution markers
    slow: Slow-running tests (may take more than 10 seconds)
    network: Tests requiring network access
    database: Tests requiring database access
    
    # Quality markers
    coverage: Code coverage related tests
    security: Security and vulnerability tests
    monitoring: Quality monitoring and alerting tests

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:*indic*
    ignore::UserWarning:*sanskrit*
    ignore::UserWarning:*gensim*
    ignore::FutureWarning:*sklearn*
    error::UserWarning:*test*

# Logging configuration for tests
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/test_execution.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d %(funcName)s(): %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test timeout (30 minutes for comprehensive test suite)
timeout = 1800

# Performance testing configuration
benchmark_warmup = true
benchmark_warmup_iterations = 2
benchmark_min_rounds = 3

# Parallel testing support (requires pytest-xdist)
# Run with: pytest -n auto
# addopts = -n auto

# Quality assurance thresholds
quality_gate_coverage = 90
quality_gate_performance = 10.0  # segments per second
quality_gate_quality_score = 85.0