{
  "permissions": {
    "allow": [
      "Bash(git init:*)",
      "Bash(git remote add:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(git push:*)",
      "Bash(chmod:*)",
      "Bash(mkdir:*)",
      "Bash(python -m pytest tests/test_file_structure.py -v)",
      "Bash(python3 -m pytest tests/test_file_structure.py -v)",
      "Bash(py tests/test_file_structure.py)",
      "Bash(python -m pytest tests/test_srt_parser.py::TestSRTParser::test_parse_valid_srt_string -v)",
      "Bash(where python)",
      "Bash(py --version)",
      "Bash(python:*)",
      "Bash(py:*)",
      "Bash(where py)",
      "Bash(C:Windowspy.exe --version)",
      "Bash(C:Windowspy.exe --list)",
      "Bash(\"/c/Windows/py.exe\" --version)",
      "Bash(\"/c/Windows/py.exe\" --list)",
      "Bash(\"/c/Windows/py.exe\" -3.10 --version)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m venv .venv)",
      "Bash(.venv/Scripts/activate)",
      "Bash(source:*)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip install --upgrade pip)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip install -r requirements.txt)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip install pandas numpy pyyaml pysrt pytest click tqdm)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip install fuzzywuzzy python-Levenshtein)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_file_structure.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 src/main.py --help)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip install structlog)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.append(''src'')\nfrom utils.srt_parser import SRTParser\nparser = SRTParser()\nresult = parser.parse_file(''data/test_samples/basic_test.srt'')\nprint(''✅ SRT Parser works!'')\nprint(f''Parsed {len(result)} segments'')\nif result:\n    print(f''First segment: {result[0].text[:50]}...'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.append(''src'')\nfrom utils.srt_parser import SRTParser\nparser = SRTParser()\nresult = parser.parse_file(''data/test_samples/basic_test.srt'')\nprint(''SRT Parser works!'')\nprint(f''Parsed {len(result)} segments'')\nif result:\n    print(f''First segment: {result[0].text[:50]}...'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pip list)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_foundational_corrections_integration.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"import sys; sys.path.append(''src''); import pytest; pytest.main([''-v'', ''tests/test_foundational_corrections_integration.py''])\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.getcwd(), ''src''))\n\n# Test import\ntry:\n    from utils.srt_parser import SRTParser\n    from post_processors.sanskrit_post_processor import SanskritPostProcessor\n    print(''✅ Imports successful'')\nexcept Exception as e:\n    print(f''❌ Import error: {e}'')\n\n# Run the test\nimport subprocess\nresult = subprocess.run([sys.executable, ''-m'', ''pytest'', ''tests/test_foundational_corrections_integration.py'', ''-v''], \n                       env={**os.environ, ''PYTHONPATH'': os.path.join(os.getcwd(), ''src'')},\n                       capture_output=True, text=True)\nprint(''STDOUT:'')\nprint(result.stdout)\nprint(''STDERR:'')  \nprint(result.stderr)\nprint(f''Return code: {result.returncode}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom utils.srt_parser import SRTParser\n\n# Test basic functionality\nprocessor = SanskritPostProcessor()\nparser = SRTParser()\n\n# Test text with obvious normalization opportunities\ntest_text = ''Um, today we will discuss chapter two verse twenty five.''\nprint(f''Original: {test_text}'')\n\n# Test basic normalization\nif hasattr(processor.text_normalizer, ''normalize_with_advanced_tracking''):\n    result = processor.text_normalizer.normalize_with_advanced_tracking(test_text)\n    print(f''Normalized: {result.corrected_text}'')\n    print(f''Changes: {result.corrections_applied}'')\nelse:\n    result = processor.text_normalizer.normalize_with_tracking(test_text)\n    print(f''Normalized: {result.normalized_text}'')\n    print(f''Changes: {result.changes_applied}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Test basic functionality\nprocessor = SanskritPostProcessor()\n\n# Test text with obvious normalization opportunities\ntest_text = ''Um, today we will discuss chapter two verse twenty five.''\nprint(f''Original: {test_text}'')\n\n# Test basic normalization\nif hasattr(processor.text_normalizer, ''normalize_with_advanced_tracking''):\n    result = processor.text_normalizer.normalize_with_advanced_tracking(test_text)\n    print(f''Normalized: {result.corrected_text}'')\n    print(f''Changes: {result.corrections_applied}'')\n    print(f''Conversational fixes: {len(result.conversational_fixes)}'')\nelse:\n    result = processor.text_normalizer.normalize_with_tracking(test_text)\n    print(f''Normalized: {result.normalized_text}'')\n    print(f''Changes: {result.changes_applied}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Test basic functionality\nprocessor = SanskritPostProcessor()\n\n# Test text with obvious normalization opportunities\ntest_text = ''Um, today we will discuss chapter two verse twenty five.''\nprint(f''Original: {test_text}'')\n\n# Test basic normalization\nif hasattr(processor.text_normalizer, ''normalize_with_advanced_tracking''):\n    result = processor.text_normalizer.normalize_with_advanced_tracking(test_text)\n    print(f''Normalized: {result.corrected_text}'')\n    print(f''Changes: {result.corrections_applied}'')\n    print(f''Conversational fixes: {len(result.conversational_fixes)}'')\nelse:\n    result = processor.text_normalizer.normalize_with_tracking(test_text)\n    print(f''Normalized: {result.normalized_text}'')\n    print(f''Changes: {result.changes_applied}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Test basic functionality\nprocessor = SanskritPostProcessor()\n\n# Test text with obvious normalization opportunities\ntest_text = ''Um, today we will discuss chapter two verse twenty five.''\nprint(f''Original: {test_text}'')\n\n# Test basic normalization\nif hasattr(processor.text_normalizer, ''normalize_with_advanced_tracking''):\n    result = processor.text_normalizer.normalize_with_advanced_tracking(test_text)\n    print(f''Normalized: {result.corrected_text}'')\n    print(f''Changes: {result.corrections_applied}'')\n    print(f''Conversational fixes: {len(result.conversational_fixes)}'')\nelse:\n    result = processor.text_normalizer.normalize_with_tracking(test_text)\n    print(f''Normalized: {result.normalized_text}'')\n    print(f''Changes: {result.changes_applied}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Test basic functionality\nprocessor = SanskritPostProcessor()\n\n# Test text with obvious normalization opportunities\ntest_text = ''Um, today we will discuss chapter two verse twenty five.''\nprint(f''Original: {test_text}'')\n\nresult = processor.text_normalizer.normalize_with_advanced_tracking(test_text)\nprint(f''Normalized: {result.corrected_text}'')\nprint(f''Changes: {result.corrections_applied}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_foundational_corrections_integration.py::TestFoundationalCorrectionsIntegration::test_conversational_patterns_end_to_end -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Create a test SRT file\nprocessor = SanskritPostProcessor()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.''''''\n\n# Write to temp file\nwith tempfile.NamedTemporaryFile(mode=''w'', suffix=''.srt'', delete=False, encoding=''utf-8'') as f:\n    f.write(test_content)\n    temp_input = f.name\n\ntemp_output = temp_input.replace(''.srt'', ''_out.srt'')\n\ntry:\n    print(''Processing SRT file...'')\n    metrics = processor.process_srt_file(Path(temp_input), Path(temp_output))\n    \n    print(f''Total segments: {metrics.total_segments}'')\n    print(f''Segments modified: {metrics.segments_modified}'')\n    print(f''Processing time: {metrics.processing_time:.3f}s'')\n    \n    # Check if output file exists and read it\n    if os.path.exists(temp_output):\n        with open(temp_output, ''r'', encoding=''utf-8'') as f:\n            output = f.read()\n        print(''Output content:'')\n        print(repr(output))\n    else:\n        print(''Output file not created!'')\n        \nfinally:\n    # Cleanup\n    if os.path.exists(temp_input):\n        os.unlink(temp_input)\n    if os.path.exists(temp_output):\n        os.unlink(temp_output)\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom utils.srt_parser import SRTParser\n\n# Create a test \nprocessor = SanskritPostProcessor()\nparser = SRTParser()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.''''''\n\n# Parse the content\nsegments = parser.parse_string(test_content)\nprint(f''Original segment text: {repr(segments[0].text)}'')\n\n# Process one segment directly\nprocessed_segment = processor._process_srt_segment(segments[0], processor.metrics_collector.create_file_metrics(''test''))\nprint(f''Processed segment text: {repr(processed_segment.text)}'')\n\nprint(f''Are they equal? {segments[0].text == processed_segment.text}'')\nprint(f''Text changed? {segments[0].text != processed_segment.text}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom utils.srt_parser import SRTParser\n\n# Create a test \nprocessor = SanskritPostProcessor()\nparser = SRTParser()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.''''''\n\n# Parse the content\nsegments = parser.parse_string(test_content)\nprint(f''Original segment text: {repr(segments[0].text)}'')\n\n# Process one segment directly\nprocessed_segment = processor._process_srt_segment(segments[0], processor.metrics_collector.create_file_metrics(''test''))\nprint(f''Processed segment text: {repr(processed_segment.text)}'')\n\nprint(f''Are they equal? {segments[0].text == processed_segment.text}'')\nprint(f''Text changed? {segments[0].text != processed_segment.text}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom utils.srt_parser import SRTParser\n\n# Create a test \nprocessor = SanskritPostProcessor()\nparser = SRTParser()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.''''''\n\n# Parse the content\nsegments = parser.parse_string(test_content)\noriginal_text = segments[0].text\nprint(f''Original segment text: {repr(original_text)}'')\n\n# Process one segment directly\nprocessed_segment = processor._process_srt_segment(segments[0], processor.metrics_collector.create_file_metrics(''test''))\nprocessed_text = processed_segment.text\nprint(f''Processed segment text: {repr(processed_text)}'')\n\nprint(f''Are they equal? {original_text == processed_text}'')\ntext_changed = original_text != processed_text\nprint(f''Text changed? {text_changed}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom utils.srt_parser import SRTParser\n\n# Create a test \nprocessor = SanskritPostProcessor()\nparser = SRTParser()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.''''''\n\n# Parse the content\nsegments = parser.parse_string(test_content)\noriginal_text = segments[0].text\nprint(f''Original segment text: {repr(original_text)}'')\n\n# Process one segment directly\nprocessed_segment = processor._process_srt_segment(segments[0], processor.metrics_collector.create_file_metrics(''test''))\nprocessed_text = processed_segment.text\nprint(f''Processed segment text: {repr(processed_text)}'')\n\nprint(f''Are they equal? {original_text == processed_text}'')\ntext_changed = original_text != processed_text\nprint(f''Text changed? {text_changed}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_segment.py)",
      "Bash(rm:*)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.text_normalizer import TextNormalizer\n\nnormalizer = TextNormalizer()\n\ntest_text = ''chapter two verse twenty five''\nprint(f''Original: {test_text}'')\n\nresult = normalizer.convert_numbers(test_text)\nprint(f''Result: {result}'')\n\n# Test step by step\nprint(''\\nStep by step:'')\nprint(''1. Compound numbers first:'')\nafter_compound = normalizer._convert_compound_numbers(test_text)\nprint(f''   After compound: {after_compound}'')\n\nprint(''2. Year patterns:'')\nafter_years = normalizer._convert_year_patterns(after_compound)\nprint(f''   After years: {after_years}'')\n\nprint(''3. Ordinals:'')\nafter_ordinals = normalizer._convert_ordinals(after_years)\nprint(f''   After ordinals: {after_ordinals}'')\n\nprint(''4. Basic numbers:'')\nfinal = after_ordinals\nfor word_num, digit in normalizer.basic_numbers.items():\n    import re\n    pattern = rf''\\b{re.escape(word_num)}\\b''\n    new_final = re.sub(pattern, digit, final, flags=re.IGNORECASE)\n    if new_final != final:\n        print(f''   {word_num} -> {digit}: {final} -> {new_final}'')\n        final = new_final\nprint(f''   Final: {final}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_numbers.py)",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_full.py)",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_exact.py)",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_order.py)",
      "Bash(\"/c/Windows/py.exe\" -3.10 debug_lexicon.py)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_foundational_corrections_integration.py::TestFoundationalCorrectionsIntegration::test_complex_text_processing_integration -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_conversational_patterns.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_contextual_numbers.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_advanced_text_normalizer.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.contextual_number_processor import ContextualNumberProcessor\n\nprocessor = ContextualNumberProcessor()\ntext = ''Today we study chapter two verse twenty five of the Bhagavad Gita.''\nresult = processor.process_numbers(text, ''spiritual'')\n\nprint(f''Original: {text}'')\nprint(f''Result: {result.processed_text}'')\nprint(''Conversions:'')\nfor conv in result.conversions:\n    print(f''  {conv.original} -> {conv.converted} (confidence: {conv.confidence:.2f})'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.contextual_number_processor import ContextualNumberProcessor\nimport re\n\nprocessor = ContextualNumberProcessor()\ntext = ''Today we study chapter two verse twenty five of the Bhagavad Gita.''\n\n# Test compound number pattern directly\ncompound_pattern = r''\\b(twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety)\\s+(one|two|three|four|five|six|seven|eight|nine)\\b''\nmatches = list(re.finditer(compound_pattern, text, re.IGNORECASE))\nprint(f''Compound matches found: {len(matches)}'')\nfor match in matches:\n    print(f''  Match: \"\"{match.group(0)}\"\" at position {match.start()}-{match.end()}'')\n\n# Test the individual processing methods\ncardinal_conversions = processor._process_cardinal_numbers(text)\nprint(f''Cardinal conversions: {len(cardinal_conversions)}'')\nfor conv in cardinal_conversions:\n    print(f''  {conv.original_text} -> {conv.converted_text}'')\n\nordinal_conversions = processor._process_ordinal_numbers(text)  \nprint(f''Ordinal conversions: {len(ordinal_conversions)}'')\nfor conv in ordinal_conversions:\n    print(f''  {conv.original_text} -> {conv.converted_text}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nwith open(''src/utils/contextual_number_processor.py'', ''r'', encoding=''utf-8'') as f:\n    content = f.read()\n    \n# Find _apply_conversions method\nimport re\nmatches = re.findall(r''def _apply_conversions.*?(?=def|\\Z)'', content, re.DOTALL)\nif matches:\n    print(''Found _apply_conversions method:'')\n    print(matches[0][:500] + ''...'' if len(matches[0]) > 500 else matches[0])\nelse:\n    print(''_apply_conversions method not found'')\n    \n# Check if there are any methods that might handle text replacement\napply_matches = re.findall(r''def.*apply.*\\(.*?\\):'', content)\nfor match in apply_matches:\n    print(f''Found apply-related method: {match}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.contextual_number_processor import ContextualNumberProcessor\n\nprocessor = ContextualNumberProcessor()\ntext = ''Today we study chapter two verse twenty five of the Bhagavad Gita.''\n\n# Get all conversions by type\nprint(''=== All Conversions ==='')\nscriptural = processor._process_scriptural_references(text)\nprint(f''Scriptural: {len(scriptural)}'')\nfor conv in scriptural:\n    print(f''  \"\"{conv.original_text}\"\" -> \"\"{conv.converted_text}\"\" (pos {conv.start_pos}-{conv.end_pos})'')\n\ncardinal = processor._process_cardinal_numbers(text)  \nprint(f''Cardinal: {len(cardinal)}'')\nfor conv in cardinal:\n    print(f''  \"\"{conv.original_text}\"\" -> \"\"{conv.converted_text}\"\" (pos {conv.start_pos}-{conv.end_pos})'')\n\nordinal = processor._process_ordinal_numbers(text)\nprint(f''Ordinal: {len(ordinal)}'')\nfor conv in ordinal:\n    print(f''  \"\"{conv.original_text}\"\" -> \"\"{conv.converted_text}\"\" (pos {conv.start_pos}-{conv.end_pos})'')\n\nprint(''\\n=== After resolution ==='')\nall_conversions = scriptural + cardinal + ordinal\nall_conversions.sort(key=lambda c: c.start_pos)\nresolved = processor._resolve_overlapping_conversions(all_conversions)\nprint(f''Resolved: {len(resolved)}'')\nfor conv in resolved:\n    print(f''  \"\"{conv.original_text}\"\" -> \"\"{conv.converted_text}\"\" (pos {conv.start_pos}-{conv.end_pos})'')\n\")",
      "Bash(grep:*)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.contextual_number_processor import ContextualNumberProcessor\n\nprocessor = ContextualNumberProcessor()\n\n# Test _word_to_number method with compound number\nresult1 = processor._word_to_number(''twenty five'')\nprint(f''\"\"twenty five\"\" -> {result1}'')\n\nresult2 = processor._word_to_number(''twenty'')\nprint(f''\"\"twenty\"\" -> {result2}'')\n\nresult3 = processor._word_to_number(''five'')\nprint(f''\"\"five\"\" -> {result3}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport re\n\ntext = ''Today we study chapter two verse twenty five of the Bhagavad Gita.''\npattern = r''\\bchapter\\s+(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|twenty\\s+one|twenty\\s+two|twenty\\s+three|twenty\\s+four|twenty\\s+five|twenty\\s+six|twenty\\s+seven|twenty\\s+eight|twenty\\s+nine)\\s+verse\\s+(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|twenty\\s+one|twenty\\s+two|twenty\\s+three|twenty\\s+four|twenty\\s+five|twenty\\s+six|twenty\\s+seven|twenty\\s+eight|twenty\\s+nine)\\b''\n\nmatches = list(re.finditer(pattern, text, re.IGNORECASE))\nprint(f''Matches found: {len(matches)}'')\nfor match in matches:\n    print(f''  Full match: \"\"{match.group(0)}\"\"'')\n    print(f''  Groups: {match.groups()}'')\n    print(f''  Position: {match.start()}-{match.end()}'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nsys.path.insert(0, ''src'')\nfrom utils.contextual_number_processor import ContextualNumberProcessor\n\nprocessor = ContextualNumberProcessor()\ntext = ''Today we study chapter two verse twenty five of the Bhagavad Gita.''\nresult = processor.process_numbers(text, ''spiritual'')\n\nprint(f''Original: {text}'')\nprint(f''Result: {result.processed_text}'')\nprint(''Conversions:'')\nfor conv in result.conversions:\n    print(f''  \"\"{conv.original_text}\"\" -> \"\"{conv.converted_text}\"\" (confidence: {conv.confidence_score:.2f})'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_contextual_numbers.py::TestContextualNumberProcessor::test_scriptural_reference_processing -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_advanced_text_normalizer.py::TestAdvancedTextNormalizer::test_quality_score_calculation -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Create a comprehensive test SRT with conversational patterns and number conversion\nprocessor = SanskritPostProcessor()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.\n\n2\n00:00:06,000 --> 00:00:12,000\nUh, this verse speaks about the, the eternal nature of the soul.\n\n3\n00:00:13,000 --> 00:00:18,000\nActually, let me correct that - rather, it speaks about detachment.''''''\n\n# Write to temp file\nwith tempfile.NamedTemporaryFile(mode=''w'', suffix=''.srt'', delete=False, encoding=''utf-8'') as f:\n    f.write(test_content)\n    temp_input = f.name\n\ntemp_output = temp_input.replace(''.srt'', ''_processed.srt'')\n\ntry:\n    print(''=== Processing SRT file ==='')\n    metrics = processor.process_srt_file(Path(temp_input), Path(temp_output))\n    \n    print(f''Total segments: {metrics.total_segments}'')\n    print(f''Segments modified: {metrics.segments_modified}'')\n    print(f''Processing time: {metrics.processing_time:.3f}s'')\n    print(f''Conversational fixes: {metrics.conversational_fixes}'')\n    print(f''Number conversions: {metrics.number_conversions}'')\n    \n    # Check output file\n    if os.path.exists(temp_output):\n        with open(temp_output, ''r'', encoding=''utf-8'') as f:\n            output = f.read()\n        print(''\\n=== Processed Output ==='')\n        print(output)\n    else:\n        print(''Output file not created!'')\n        \nfinally:\n    # Cleanup\n    if os.path.exists(temp_input):\n        os.unlink(temp_input)\n    if os.path.exists(temp_output):\n        os.unlink(temp_output)\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Create a comprehensive test SRT with conversational patterns and number conversion\nprocessor = SanskritPostProcessor()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss chapter two verse twenty five.\n\n2\n00:00:06,000 --> 00:00:12,000\nUh, this verse speaks about the, the eternal nature of the soul.\n\n3\n00:00:13,000 --> 00:00:18,000\nActually, let me correct that - rather, it speaks about detachment.''''''\n\n# Write to temp file\nwith tempfile.NamedTemporaryFile(mode=''w'', suffix=''.srt'', delete=False, encoding=''utf-8'') as f:\n    f.write(test_content)\n    temp_input = f.name\n\ntemp_output = temp_input.replace(''.srt'', ''_processed.srt'')\n\ntry:\n    print(''=== Processing SRT file ==='')\n    metrics = processor.process_srt_file(Path(temp_input), Path(temp_output))\n    \n    print(f''Total segments: {metrics.total_segments}'')\n    print(f''Segments modified: {metrics.segments_modified}'')\n    print(f''Processing time: {metrics.processing_time:.3f}s'')\n    print(f''Average confidence: {metrics.average_confidence:.3f}'')\n    \n    print(''\\n=== Available metrics attributes ==='')\n    for attr in dir(metrics):\n        if not attr.startswith(''_''):\n            print(f''  {attr}: {getattr(metrics, attr)}'')\n    \n    # Check output file\n    if os.path.exists(temp_output):\n        with open(temp_output, ''r'', encoding=''utf-8'') as f:\n            output = f.read()\n        print(''\\n=== Processed Output ==='')\n        print(output)\n    else:\n        print(''Output file not created!'')\n        \nfinally:\n    # Cleanup\n    if os.path.exists(temp_input):\n        os.unlink(temp_input)\n    if os.path.exists(temp_output):\n        os.unlink(temp_output)\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/test_processing_quality.py -v)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -m pytest tests/ -v --tb=short)",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Create comprehensive test SRT with all Story 1.4 features\nprocessor = SanskritPostProcessor()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss, uh, I mean we''ll explore the Bhagavad Gita chapter two verse twenty five.\n\n2\n00:00:06,000 --> 00:00:12,000\nUh, this verse speaks about the, the eternal nature of the soul, you know.\n\n3\n00:00:13,000 --> 00:00:18,000\nActually, let me correct that - rather, it speaks about detachment from outcomes.\n\n4\n00:00:19,000 --> 00:00:25,000\nIn the year two thousand five, I first studied this, um, this profound verse about, well, about spiritual wisdom.\n\n5\n00:00:26,000 --> 00:00:32,000\nThe text says, and I quote, that one should, uh, one should remain, um, unattached to results.''''''\n\n# Write to temp file\nwith tempfile.NamedTemporaryFile(mode=''w'', suffix=''.srt'', delete=False, encoding=''utf-8'') as f:\n    f.write(test_content)\n    temp_input = f.name\n\ntemp_output = temp_input.replace(''.srt'', ''_processed.srt'')\n\ntry:\n    print(''=== End-to-End SRT Processing Test ==='')\n    metrics = processor.process_srt_file(Path(temp_input), Path(temp_output))\n    \n    print(f''Total segments: {metrics.total_segments}'')\n    print(f''Segments modified: {metrics.segments_modified}'')\n    print(f''Processing time: {metrics.processing_time:.3f}s'')\n    print(f''Average confidence: {metrics.average_confidence:.3f}'')\n    \n    # Check output file\n    if os.path.exists(temp_output):\n        with open(temp_output, ''r'', encoding=''utf-8'') as f:\n            output = f.read()\n        print(''\\n=== Processed Output ==='')\n        print(output)\n        \n        # Validate corrections applied\n        corrections_found = []\n        if ''chapter 2 verse 25'' in output:\n            corrections_found.append(''✅ Number conversion: chapter two verse twenty five → chapter 2 verse 25'')\n        if ''Um,'' not in output and ''uh,'' not in output:\n            corrections_found.append(''✅ Filler word removal: Um, uh removed'')\n        if ''I mean'' not in output:\n            corrections_found.append(''✅ Rescinded phrase handling: I mean removed'')\n        if ''rather, it speaks about detachment'' in output:\n            corrections_found.append(''✅ Conversational correction: rather clause handled'')\n        if ''2005'' in output:\n            corrections_found.append(''✅ Year conversion: two thousand five → 2005'')\n            \n        print(''\\n=== Corrections Validation ==='')\n        for correction in corrections_found:\n            print(correction)\n        \n        print(f''\\n=== Processing Success Rate: {len(corrections_found)}/5 expected corrections ==='')\n    else:\n        print(''❌ Output file not created!'')\n        \nfinally:\n    # Cleanup\n    if os.path.exists(temp_input):\n        os.unlink(temp_input)\n    if os.path.exists(temp_output):\n        os.unlink(temp_output)\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\nimport sys\nimport tempfile\nimport os\nfrom pathlib import Path\nsys.path.insert(0, ''src'')\n\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\n\n# Create comprehensive test SRT with all Story 1.4 features\nprocessor = SanskritPostProcessor()\n\ntest_content = ''''''1\n00:00:01,000 --> 00:00:05,000\nUm, today we will discuss, uh, I mean we will explore the Bhagavad Gita chapter two verse twenty five.\n\n2\n00:00:06,000 --> 00:00:12,000\nUh, this verse speaks about the, the eternal nature of the soul, you know.\n\n3\n00:00:13,000 --> 00:00:18,000\nActually, let me correct that - rather, it speaks about detachment from outcomes.\n\n4\n00:00:19,000 --> 00:00:25,000\nIn the year two thousand five, I first studied this, um, this profound verse about, well, about spiritual wisdom.\n\n5\n00:00:26,000 --> 00:00:32,000\nThe text says, and I quote, that one should, uh, one should remain, um, unattached to results.''''''\n\n# Write to temp file\nwith tempfile.NamedTemporaryFile(mode=''w'', suffix=''.srt'', delete=False, encoding=''utf-8'') as f:\n    f.write(test_content)\n    temp_input = f.name\n\ntemp_output = temp_input.replace(''.srt'', ''_processed.srt'')\n\ntry:\n    print(''=== End-to-End SRT Processing Test ==='')\n    metrics = processor.process_srt_file(Path(temp_input), Path(temp_output))\n    \n    print(f''Total segments: {metrics.total_segments}'')\n    print(f''Segments modified: {metrics.segments_modified}'')\n    print(f''Processing time: {metrics.processing_time:.3f}s'')\n    print(f''Average confidence: {metrics.average_confidence:.3f}'')\n    \n    # Check output file\n    if os.path.exists(temp_output):\n        with open(temp_output, ''r'', encoding=''utf-8'') as f:\n            output = f.read()\n        print('''')\n        print(''=== Processed Output ==='')\n        print(output)\n        \n        # Validate corrections applied\n        corrections_found = []\n        if ''chapter 2 verse 25'' in output:\n            corrections_found.append(''Number conversion: chapter two verse twenty five -> chapter 2 verse 25'')\n        if ''Um,'' not in output and ''uh,'' not in output:\n            corrections_found.append(''Filler word removal: Um, uh removed'')\n        if ''I mean'' not in output:\n            corrections_found.append(''Rescinded phrase handling: I mean removed'')\n        if ''rather, it speaks about detachment'' in output:\n            corrections_found.append(''Conversational correction: rather clause handled'')\n        if ''2005'' in output:\n            corrections_found.append(''Year conversion: two thousand five -> 2005'')\n            \n        print('''')\n        print(''=== Corrections Validation ==='')\n        for correction in corrections_found:\n            print(f''- {correction}'')\n        \n        print(f'''')\n        print(f''Processing Success Rate: {len(corrections_found)}/5 expected corrections'')\n    else:\n        print(''Output file not created!'')\n        \nfinally:\n    # Cleanup\n    if os.path.exists(temp_input):\n        os.unlink(temp_input)\n    if os.path.exists(temp_output):\n        os.unlink(temp_output)\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\n# Test the specific test sample files\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom pathlib import Path\n\nprocessor = SanskritPostProcessor()\n\n# Test conversational patterns sample\nconv_file = Path(''data/test_samples/conversational_test.srt'')\nif conv_file.exists():\n    print(''=== Testing conversational_test.srt ==='')\n    conv_output = conv_file.with_suffix('''').with_suffix(''.processed.srt'')\n    metrics1 = processor.process_srt_file(conv_file, conv_output)\n    print(f''Segments: {metrics1.total_segments}, Modified: {metrics1.segments_modified}'')\n    \n    if conv_output.exists():\n        with open(conv_output, ''r'', encoding=''utf-8'') as f:\n            print(''Output:'')\n            print(f.read())\nelse:\n    print(''conversational_test.srt not found'')\n\nprint()\n\n# Test numbers context sample  \nnumbers_file = Path(''data/test_samples/numbers_context_test.srt'')\nif numbers_file.exists():\n    print(''=== Testing numbers_context_test.srt ==='')\n    numbers_output = numbers_file.with_suffix('''').with_suffix(''.processed.srt'')\n    metrics2 = processor.process_srt_file(numbers_file, numbers_output)\n    print(f''Segments: {metrics2.total_segments}, Modified: {metrics2.segments_modified}'')\n    \n    if numbers_output.exists():\n        with open(numbers_output, ''r'', encoding=''utf-8'') as f:\n            print(''Output:'')\n            print(f.read())\nelse:\n    print(''numbers_context_test.srt not found'')\n\")",
      "Bash(\"/c/Windows/py.exe\" -3.10 -c \"\n# Process the numbers context test file\nimport sys\nsys.path.insert(0, ''src'')\nfrom post_processors.sanskrit_post_processor import SanskritPostProcessor\nfrom pathlib import Path\n\nprocessor = SanskritPostProcessor()\n\nnumbers_file = Path(''data/test_samples/numbers_context_test.srt'')\nnumbers_output = numbers_file.parent / ''numbers_context_test.processed.srt''\n\nprint(''=== Processing numbers_context_test.srt ==='')\nmetrics = processor.process_srt_file(numbers_file, numbers_output)\nprint(f''Segments: {metrics.total_segments}, Modified: {metrics.segments_modified}, Confidence: {metrics.average_confidence:.3f}'')\n\")"
    ],
    "deny": []
  }
}