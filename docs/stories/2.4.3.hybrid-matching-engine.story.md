# Story 2.4.3: Hybrid Matching Engine - Core 3-Stage Pipeline

## Status
Draft

## Story
**As a** Yoga Vedanta transcript processor,  
**I want** a comprehensive 3-stage matching pipeline (phonetic → sequence alignment → semantic similarity) for scripture verse identification,  
**so that** the system achieves research-grade accuracy in matching noisy ASR transcripts to canonical scriptural verses.

## Acceptance Criteria

1. The system implements a 3-stage matching pipeline: phonetic hashing → Smith-Waterman sequence alignment → semantic similarity
2. The system can filter scripture candidates using Sanskrit-specific phonetic hashing for fast Stage 1 filtering
3. The system can perform Smith-Waterman sequence alignment for Stage 2 precision matching of noisy ASR text
4. The system can compute Stage 3 semantic similarity using iNLTK embeddings from Story 2.4.2
5. The system provides weighted composite confidence scoring combining all three stages
6. The system integrates seamlessly with existing Story 2.3 ScriptureProcessor and maintains full backward compatibility
7. The system handles Gold/Silver/Bronze source provenance classification from research blueprint
8. The system gracefully falls back to existing Story 2.3 functionality if advanced components fail
9. All existing Story 2.3 scripture processing functionality continues to work unchanged

## Tasks / Subtasks

- [ ] Implement HybridMatchingEngine core component (AC: 1,5,6)
  - [ ] Create HybridMatchingEngine class in `src/scripture_processing/hybrid_matching_engine.py`
  - [ ] Implement match_verse_passage() method with 3-stage pipeline
  - [ ] Add weighted composite confidence scoring algorithm
  - [ ] Integrate with existing ScriptureProcessor as enhancement layer

- [ ] Implement Stage 1: Sanskrit Phonetic Hashing (AC: 2)
  - [ ] Create SanskritPhoneticHasher in `src/utils/sanskrit_phonetic_hasher.py`
  - [ ] Implement Sanskrit-specific phonetic encoding algorithm
  - [ ] Create phonetic hash lookup indexes for existing scripture database
  - [ ] Add get_phonetic_candidates() method for fast filtering

- [ ] Implement Stage 2: Smith-Waterman Sequence Alignment (AC: 3)
  - [ ] Create SequenceAlignmentEngine in `src/utils/sequence_alignment_engine.py`  
  - [ ] Implement Smith-Waterman algorithm using genalog library
  - [ ] Add calculate_sequence_alignment() method
  - [ ] Optimize for Sanskrit text with IAST character handling

- [ ] Implement Stage 3: Semantic Similarity Integration (AC: 4)
  - [ ] Integrate SemanticSimilarityCalculator from Story 2.4.2
  - [ ] Add compute_semantic_similarity() method to pipeline
  - [ ] Implement semantic embedding lookup for scripture verses
  - [ ] Handle embedding cache misses gracefully

- [ ] Implement HybridMatchingResult data model (AC: 5,7)
  - [ ] Create HybridMatchingResult class from architecture specification
  - [ ] Add phonetic_score, sequence_alignment_score, semantic_similarity_score fields
  - [ ] Implement composite_confidence calculation with source_provenance weighting
  - [ ] Add processing_metadata for pipeline debugging

- [ ] Integration with existing Story 2.3 components (AC: 6,8,9)
  - [ ] Extend ScriptureProcessor with hybrid matching capabilities
  - [ ] Enhance VerseSelectionSystem with HybridMatchingResult support
  - [ ] Maintain full backward compatibility with existing verse selection API
  - [ ] Implement feature flag for hybrid matching enable/disable

- [ ] Source provenance and quality management (AC: 7)
  - [ ] Implement Gold/Silver/Bronze classification system
  - [ ] Add source_provenance field to scripture YAML schema
  - [ ] Create provenance-weighted confidence scoring
  - [ ] Add provenance validation and reporting

- [ ] Testing and validation (All AC)
  - [ ] Unit tests for each stage of the 3-stage pipeline
  - [ ] Integration tests with existing Story 2.3 functionality
  - [ ] Performance benchmarks against existing basic matching
  - [ ] Regression tests ensuring no existing functionality breaks
  - [ ] End-to-end tests with real ASR transcript samples

## Dev Notes

### Architecture Integration Points
Based on `docs/scripture-enhancement-architecture.md`:

**Component Location**: `src/scripture_processing/hybrid_matching_engine.py` (line 240)
**Integration Strategy**: Layer enhancement pattern around existing ScriptureProcessor, CanonicalTextManager, and verse selection systems (lines 392-394)
**Core Responsibility**: Implement research blueprint algorithms within established codebase (lines 158-167)

**Key Architecture Requirements:**
- **3-Stage Pipeline**: Phonetic → Sequence Alignment → Semantic (lines 159-167)
- **Component Dependencies**: SanskritPhoneticHasher, SequenceAlignmentEngine, SemanticSimilarityCalculator
- **Data Models**: HybridMatchingResult (lines 86-98), enhanced scripture YAML schema (lines 129-152)
- **Backward Compatibility**: Full API compatibility with existing Story 2.3 interface (lines 51-52)

**Technology Integration:**
- **Phonetic Hashing**: Sanskrit-specific phonetic encoding (lines 168-170)
- **Sequence Alignment**: Smith-Waterman via genalog library (line 80)  
- **Semantic Similarity**: iNLTK integration from Story 2.4.2 (lines 172-174)
- **File-Based Architecture**: Enhanced YAML with semantic vectors and phonetic hashes (lines 136-147)

**Cross-Component Enhancement:**
This is the core integration hub that coordinates all research algorithms with existing Story 2.3 scripture processing while enabling cross-story enhancements for Stories 2.1 and 2.2 (lines 180-200)

### Testing
- **Test Location**: `tests/test_hybrid_matching_engine.py` (line 264)
- **Framework**: pytest with Sanskrit linguistic test data fixtures (lines 330-339)
- **Coverage Target**: 90%+ for all research algorithm implementations
- **Key Test Categories**: Algorithm correctness, performance benchmarks, Sanskrit linguistic accuracy, fallback behavior (lines 336-339)
- **Integration Requirements**: End-to-end validation with real ASR samples, existing functionality regression testing

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-07 | 1.0 | Initial story creation based on architecture document | Sarah (Product Owner) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be recorded by dev agent*

### Debug Log References
*To be recorded by dev agent*

### Completion Notes List
*To be recorded by dev agent*

### File List
*To be recorded by dev agent*

## QA Results
*Results from QA Agent review will be recorded here*